{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spread</th>\n",
       "      <th>target_median</th>\n",
       "      <th>number_KNN</th>\n",
       "      <th>ABS Metrics</th>\n",
       "      <th>fsignal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.393</td>\n",
       "      <td>1.393</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.610</td>\n",
       "      <td>1.824</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.018</td>\n",
       "      <td>1.018</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.517</td>\n",
       "      <td>1.345</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   spread  target_median  number_KNN  ABS Metrics   fsignal\n",
       "1   1.000          1.000         1.0          0.00      0.0\n",
       "3   1.393          1.393         1.0          0.00      0.0\n",
       "5   1.610          1.824         2.0          0.12      0.0\n",
       "7   1.018          1.018         1.0          0.00      0.0\n",
       "9   2.517          1.345         4.0          0.87      0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"clean_median_metrix_data.csv\")\n",
    "data = data.dropna()\n",
    "data['spread'] = data['spread']/1000\n",
    "data['target_median'] = data['target_median']/1000\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix = data.values[:,:-1]\n",
    "weights = [1,2,3,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = data.values[:,-1]\n",
    "step_size = 10-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores =  get_score(weights,feature_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-24537.472194654125"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_log_likelihood(feature_matrix,obs,weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[111460887040859.08, 112207350253620.44, 17119976097505.06, 322992202096.92664]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_logistic_regression(feature_matrix, weights, obs,step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(weights,feature_matrix):\n",
    "    scores = np.dot(feature_matrix, weights)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate probability \n",
    "def calculate_prob(scores):\n",
    "    prob_pred = []\n",
    "    for score in scores:\n",
    "        prob = 1/(1+math.exp(-score))\n",
    "        prob_pred.append(prob)\n",
    "    return prob_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get accuracy \n",
    "def get_classification_accuracy(pred, obs):\n",
    "    num_correct = sum(pred==obs)\n",
    "    accuracy = num_correct/len(pred)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute derivative of log likelihood with respect to a single coefficient \n",
    "def calculate_log_likelihood(feature_matrix,obs,weights):\n",
    "    pred = np.dot(feature_matrix, weights)\n",
    "    logexp = 1/(1+np.exp(-pred))\n",
    "    lp = np.sum((obs -1)*pred - logexp)\n",
    "    return lp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression -- gradient descent \n",
    "# 1. gradient function \n",
    "# 2.logistic regression \n",
    "def get_gradient(error,feature_matrix):\n",
    "    derivatives = np.dot(error,feature_matrix)\n",
    "    return derivatives \n",
    "\n",
    "def get_logistic_regression(feature_matrix, weights, obs,step_size):\n",
    "    D = feature_matrix.shape[1]\n",
    "    pred = np.dot(feature_matrix, weights)\n",
    "    error = obs - pred\n",
    "    for j in range(D):\n",
    "        derivatives = get_gradient(error,feature_matrix[:,j])\n",
    "        weights[j] += step_size * derivatives\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build decision tree\n",
    "# 1. count number of mistake while predicting marjority class \n",
    "def intermediate_node_num_mistake(labels_in_node):\n",
    "    if (len(labels_in_node) == 0):\n",
    "        return 0\n",
    "    num_positive = (labels_in_node == 1).sum()\n",
    "    num_negative = (labels_in_node == -1).sum()\n",
    "    return num_negative if num_positive > num_negative else num_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "##2. pick up best feature to split \n",
    "def best_spliting_feature(data,features, target):\n",
    "    best_feature = []\n",
    "    best_error = 10\n",
    "    num_record = len(data)\n",
    "    \n",
    "    for feature in features:\n",
    "        right_size = data[data[feature] == 1]\n",
    "        left_side = data[data[feature] == 0]\n",
    "        left_mistake  =  intermediate_node_num_mistake(left_side)\n",
    "        right_mistake = intermediate_node_num_mistake(right_side)\n",
    "        avg_mistake = (left_mistake+ right_mistake)/num_record\n",
    "        if avg_mistake< best_error:\n",
    "            best_error = avg_mistake\n",
    "            best_feature = feature \n",
    "    return best_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. create leaf \n",
    "def create_leaf(target_value):\n",
    "    leaf = {\"spliting feature\": None,\n",
    "           \"left\" : None,\n",
    "            \"right\" : None,\n",
    "            \"is_leaf\":True\n",
    "           }\n",
    "    num_ones = len(target_values[target_values == 1])\n",
    "    num_minus_ones = len(target_values[target_value == -1])\n",
    "    \n",
    "    if num_ones> num_minus_one:\n",
    "        leaf['prediction'] = 1\n",
    "    else:\n",
    "        leaf['prediction'] = -1\n",
    "    return leaf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## stoping condition 1: all points in a node are in the same class \n",
    "## stoping condition 2: no  more feature \n",
    "## stoping condition 3: max depth \n",
    "def decision_tre_create(data, features,'safe_loan',max_depth = 3):\n",
    "    remaining_feature = feature[:]\n",
    "    target_values = data[target]\n",
    "    print('--------------------------------------------------------------------------')\n",
    "    print(\"subtree , depth = %s(%s data pints).\") %(current_depth, len(target_values))\n",
    "    \n",
    "    if intermediate_node_num_mistake(labels_in_node) == 0:\n",
    "        print(\"stop condition 1 reached\")\n",
    "        return create_leaf(target_values)\n",
    "    \n",
    "    if remaining_feature == []:\n",
    "        print(\"stop condiction 2 reached\")\n",
    "        return create_leaf(target_values)\n",
    "    if current_depth >= max_depth:\n",
    "        print(\"reached maximum depth. stop for now\")\n",
    "        return create(targe_values)\n",
    "    ## fine the best splitting feature \n",
    "    splitting_feature = best_spliting_feature(data,features, target)\n",
    "    left_split = data[data[splitting_feature] == 0]\n",
    "    right_split = data[data[splitting_feature] == 1]\n",
    "    remaining_feature.remove(spliting_feature)\n",
    "    print(\"split on feature %s.(%s ,%s)\"%(splitting_feature,len(left_split),len(right_split)))\n",
    "    \n",
    "    if len(left_split) == len(data):\n",
    "        print(\"create leaf node\")\n",
    "        return create_leaf(left_split[target])\n",
    "    if len(right_split) == len(data):\n",
    "        print(\"create leaf node\")\n",
    "        return create_leaf(right_split[target])\n",
    "    \n",
    "    # repeat on left and right subtree\n",
    "    left_tree = decision_tree_create\n",
    "    right_tree = decicsion_tree_create \n",
    "    return {\"is_leaf\"          : False,\n",
    "            \"predction\"        : None,\n",
    "            \"spllting_feature\" : splitting_feature,\n",
    "            \"left\"             : left_tree, \n",
    "            \"right\"            :right_tree\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cout_node(tree):\n",
    "    if tree[\"is_leaf\"]:\n",
    "        return 1\n",
    "    return 1 + count_nodes(tree['left']) + count_node(tree['right'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
